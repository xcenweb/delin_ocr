import { ref, computed } from 'vue'
import cvReadyPromise from '@techstark/opencv-js'

// OpenCV ç±»å‹å®šä¹‰
interface Point {
    x: number;
    y: number;
}

interface Corners {
    topLeftCorner: Point | null;
    topRightCorner: Point | null;
    bottomLeftCorner: Point | null;
    bottomRightCorner: Point | null;
}

let cv: any

// OpenCV æ£€æµ‹ç›¸å…³å˜é‡å’Œå¸¸é‡
let isProcessing = false
let lastValidCorners: Point[] | null = null
let detectionHistory: Point[][] = []
let stableCount = 0
let noUpdateCount = 0

const DETECTION_CONFIG = {
    MAX_HISTORY: 3,
    STABLE_THRESHOLD: 2,
    MOVE_THRESHOLD: 20,
    MAX_NO_UPDATE: 15,
    FRAME_RATE: 30,
    CANVAS_STYLE: { strokeStyle: 'pink', lineWidth: 4 }
} as const

// è§†é¢‘å’Œå®¹å™¨å°ºå¯¸
const videoWidth = ref(0)
const videoHeight = ref(0)
const containerWidth = ref(0)
const containerHeight = ref(0)

// è®¡ç®—å®é™…æ˜¾ç¤ºåŒºåŸŸï¼ˆobject-fit: containçš„æ˜¾ç¤ºåŒºåŸŸï¼‰
const displayArea = computed(() => {
    if (!videoWidth.value || !videoHeight.value || !containerWidth.value || !containerHeight.value) {
        return { left: 0, top: 0, width: 0, height: 0, scaleX: 1, scaleY: 1 }
    }

    const videoAspect = videoWidth.value / videoHeight.value
    const containerAspect = containerWidth.value / containerHeight.value

    let displayWidth, displayHeight, left, top

    if (videoAspect > containerAspect) {
        // è§†é¢‘æ›´å®½ï¼Œä»¥å®¹å™¨å®½åº¦ä¸ºå‡†
        displayWidth = containerWidth.value
        displayHeight = containerWidth.value / videoAspect
        left = 0
        top = (containerHeight.value - displayHeight) / 2
    } else {
        // è§†é¢‘æ›´é«˜ï¼Œä»¥å®¹å™¨é«˜åº¦ä¸ºå‡†
        displayWidth = containerHeight.value * videoAspect
        displayHeight = containerHeight.value
        left = (containerWidth.value - displayWidth) / 2
        top = 0
    }

    const scaleX = displayWidth / videoWidth.value
    const scaleY = displayHeight / videoHeight.value

    return { left, top, width: displayWidth, height: displayHeight, scaleX, scaleY }
})

// OpenCV å·¥å…·å‡½æ•°
const scanner = {
    // è®¡ç®—ä¸¤ç‚¹é—´è·ç¦»
    distance(p1: Point, p2: Point): number {
        return Math.hypot(p1.x - p2.x, p1.y - p2.y)
    },

    // è®¡ç®—ä¸¤ç»„ç‚¹ä¹‹é—´çš„å¹³å‡è·ç¦»
    averageDistanceBetweenPoints(points1: Point[], points2: Point[]): number {
        if (points1.length !== points2.length) return Infinity

        let totalDistance = 0
        for (let i = 0; i < points1.length; i++) {
            totalDistance += this.distance(points1[i], points2[i])
        }
        return totalDistance / points1.length
    },

    // å¹³æ»‘å¤„ç†è§’ç‚¹
    smoothCorners(newCorners: Point[]): Point[] {
        if (detectionHistory.length === 0) return newCorners

        return newCorners.map((_, i) => {
            let sumX = newCorners[i].x
            let sumY = newCorners[i].y
            detectionHistory.forEach((history: { x: number; y: number }[]) => {
                sumX += history[i].x
                sumY += history[i].y
            })

            return {
                x: sumX / (detectionHistory.length + 1),
                y: sumY / (detectionHistory.length + 1)
            }
        })
    },

    // è·å–è½®å»“çš„å››ä¸ªè§’ç‚¹
    getCornerPoints(contour: any): Corners {
        const rect = cv.minAreaRect(contour)
        const center = { x: rect.center.x, y: rect.center.y }

        const corners: Corners = {
            topLeftCorner: null,
            topRightCorner: null,
            bottomLeftCorner: null,
            bottomRightCorner: null
        }
        const maxDists = {
            topLeft: 0,
            topRight: 0,
            bottomLeft: 0,
            bottomRight: 0
        }

        for (let i = 0; i < contour.data32S.length; i += 2) {
            const point = {
                x: contour.data32S[i],
                y: contour.data32S[i + 1]
            }
            const dist = this.distance(point, center)

            if (point.x < center.x && point.y < center.y && dist > maxDists.topLeft) {
                corners.topLeftCorner = point
                maxDists.topLeft = dist
            } else if (point.x > center.x && point.y < center.y && dist > maxDists.topRight) {
                corners.topRightCorner = point
                maxDists.topRight = dist
            } else if (point.x < center.x && point.y > center.y && dist > maxDists.bottomLeft) {
                corners.bottomLeftCorner = point
                maxDists.bottomLeft = dist
            } else if (point.x > center.x && point.y > center.y && dist > maxDists.bottomRight) {
                corners.bottomRightCorner = point
                maxDists.bottomRight = dist
            }
        }

        return corners
    },

    // éªŒè¯è½®å»“æ˜¯å¦ä¸ºæœ‰æ•ˆçš„æ–‡æ¡£å½¢çŠ¶
    isValidDocumentContour(contour: any, width: number, height: number): boolean {
        const area = cv.contourArea(contour)
        // é™ä½æœ€å°é¢ç§¯è¦æ±‚ï¼Œé€‚åº”ä¹¦æœ¬å†…é¡µç­‰è¾ƒå°ç›®æ ‡
        const minArea = Math.max(2000, (width * height) * 0.05)
        if (area < minArea || area > (width * height * 0.95)) return false

        const rect = cv.boundingRect(contour)
        const rectArea = rect.width * rect.height
        // æ”¾å®½é¢ç§¯æ¯”ä¾‹è¦æ±‚ï¼Œé€‚åº”ä¸è§„åˆ™å½¢çŠ¶
        if (area / rectArea < 0.3) return false

        // æ”¾å®½å®½é«˜æ¯”é™åˆ¶ï¼Œé€‚åº”å„ç§ä¹¦æœ¬å°ºå¯¸
        const contourAspectRatio = Math.max(rect.width, rect.height) / Math.min(rect.width, rect.height)
        if (contourAspectRatio > 10) return false

        // æ·»åŠ å°ºå¯¸æ£€æŸ¥ï¼Œç¡®ä¿è½®å»“è¶³å¤Ÿå¤§
        const minDimension = Math.min(width, height) * 0.1
        if (rect.width < minDimension || rect.height < minDimension) return false

        return true
    }
}

// åœ¨ canvas ä¸Šç»˜åˆ¶è½®å»“
function drawContourOnCanvas(points: Point[], ctx: CanvasRenderingContext2D) {
    if (!ctx || points.length !== 4) return

    const { strokeStyle, lineWidth } = DETECTION_CONFIG.CANVAS_STYLE
    ctx.strokeStyle = strokeStyle
    ctx.lineWidth = lineWidth
    ctx.setLineDash([])

    ctx.beginPath()
    ctx.moveTo(points[0].x, points[0].y)
    points.slice(1).forEach((p: { x: number; y: number }) => ctx.lineTo(p.x, p.y))
    ctx.closePath()
    ctx.stroke()
}

// å¤„ç†å•å¸§è§†é¢‘
function processVideoFrame(
    videoElement: HTMLVideoElement,
    canvasElement: HTMLCanvasElement,
    ctx: CanvasRenderingContext2D,
    stream: MediaStream | undefined
) {
    if (!isProcessing || !stream || !videoElement || videoElement.readyState !== 4) {
        isProcessing = false
        return
    }

    try {
        if (!ctx || !canvasElement) return

        ctx.drawImage(videoElement, 0, 0, canvasElement.width, canvasElement.height)
        const imageData = ctx.getImageData(0, 0, canvasElement.width, canvasElement.height)
        const src = cv.matFromImageData(imageData)

        const edges = new cv.Mat()
        const blurred = new cv.Mat()
        const thresh = new cv.Mat()
        const contours = new cv.MatVector()
        const hierarchy = new cv.Mat()

        try {
            // å›¾åƒå¤„ç†æµæ°´çº¿
            const gray = new cv.Mat()
            cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY)

            // å¢å¼ºå¯¹æ¯”åº¦
            const enhanced = new cv.Mat()
            cv.equalizeHist(gray, enhanced)

            // è‡ªé€‚åº”é«˜æ–¯æ¨¡ç³Š
            cv.GaussianBlur(enhanced, blurred, new cv.Size(3, 3), 0)

            // é™ä½Cannyé˜ˆå€¼ä»¥æ•è·æ›´å¤šè¾¹ç¼˜ï¼Œç‰¹åˆ«é€‚åˆä¹¦æœ¬å†…é¡µ
            cv.Canny(blurred, edges, 30, 100)

            // ä½¿ç”¨æ›´å¤§çš„å½¢æ€å­¦æ ¸æ¥è¿æ¥æ–­å¼€çš„è¾¹ç¼˜
            const kernel = cv.getStructuringElement(cv.MORPH_RECT, new cv.Size(7, 7))
            cv.morphologyEx(edges, edges, cv.MORPH_CLOSE, kernel)

            // å†æ¬¡è†¨èƒ€ä»¥å¢å¼ºè¾¹ç¼˜è¿æ¥
            const dilateKernel = cv.getStructuringElement(cv.MORPH_RECT, new cv.Size(3, 3))
            cv.dilate(edges, edges, dilateKernel)

            cv.findContours(edges, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)

            enhanced.delete()
            dilateKernel.delete()

            ctx.clearRect(0, 0, canvasElement.width, canvasElement.height)

            // æŸ¥æ‰¾æ‰€æœ‰æœ‰æ•ˆè½®å»“å¹¶é€‰æ‹©æœ€ä½³çš„
            const validContours = []
            for (let i = 0; i < contours.size(); ++i) {
                const contour = contours.get(i)
                const area = cv.contourArea(contour)
                if (scanner.isValidDocumentContour(contour, canvasElement.width, canvasElement.height)) {
                    validContours.push({ contour, area })
                } else {
                    contour.delete()
                }
            }

            // æŒ‰é¢ç§¯æ’åºï¼Œé€‰æ‹©æœ€å¤§çš„æœ‰æ•ˆè½®å»“
            validContours.sort((a, b) => b.area - a.area)
            let maxContour = null
            if (validContours.length > 0) {
                maxContour = validContours[0].contour
                // æ¸…ç†å…¶ä»–è½®å»“
                for (let i = 1; i < validContours.length; i++) {
                    validContours[i].contour.delete()
                }
            }

            // å¤„ç†æœ€å¤§è½®å»“
            let currentCorners = null
            if (maxContour) {
                const perimeter = cv.arcLength(maxContour, true)
                const approx = new cv.Mat()
                cv.approxPolyDP(maxContour, approx, 0.02 * perimeter, true)

                if (approx.rows === 4) {
                    const { topLeftCorner, topRightCorner, bottomLeftCorner, bottomRightCorner } = scanner.getCornerPoints(maxContour)
                    const corners = [topLeftCorner, topRightCorner, bottomRightCorner, bottomLeftCorner]
                    if (corners.every(p => p)) currentCorners = corners as Point[]
                }
                approx.delete()
                maxContour.delete()
            }

            // ç¨³å®šæ€§å¤„ç†ä¸è¶…æ—¶æœºåˆ¶
            let displayCorners = null

            if (currentCorners) {
                noUpdateCount = 0
                const smoothedCorners = scanner.smoothCorners(currentCorners)

                if (lastValidCorners) {
                    const avgDistance = scanner.averageDistanceBetweenPoints(smoothedCorners, lastValidCorners)

                    if (avgDistance < DETECTION_CONFIG.MOVE_THRESHOLD) {
                        stableCount++
                        if (stableCount >= DETECTION_CONFIG.STABLE_THRESHOLD) {
                            displayCorners = smoothedCorners
                            lastValidCorners = [...smoothedCorners]
                            detectionHistory.push([...smoothedCorners])
                            detectionHistory.length > DETECTION_CONFIG.MAX_HISTORY && detectionHistory.shift()
                        } else {
                            displayCorners = lastValidCorners
                        }
                    } else {
                        stableCount = 1
                        displayCorners = smoothedCorners
                        lastValidCorners = [...smoothedCorners]
                        detectionHistory.push([...smoothedCorners])
                        detectionHistory.length > DETECTION_CONFIG.MAX_HISTORY && detectionHistory.shift()
                    }
                } else {
                    displayCorners = smoothedCorners
                    lastValidCorners = [...smoothedCorners]
                    detectionHistory.push([...smoothedCorners])
                    stableCount = 1
                }
            } else {
                noUpdateCount++

                if (lastValidCorners) {
                    displayCorners = lastValidCorners
                    stableCount = 0

                    if (noUpdateCount > DETECTION_CONFIG.MAX_NO_UPDATE) {
                        lastValidCorners = null
                        detectionHistory = []
                        stableCount = 0
                        noUpdateCount = 0
                    }
                }
            }

            // ç»˜åˆ¶è½®å»“
            displayCorners && drawContourOnCanvas(displayCorners, ctx)

            gray.delete()
            kernel.delete()
        } catch (procErr) {
            console.error('OpenCV å¤„ç†é”™è¯¯:', procErr)
            lastValidCorners = null
            detectionHistory = []
            stableCount = 0
            noUpdateCount = 0
        } finally {
            src.delete()
            edges.delete()
            blurred.delete()
            thresh.delete()
            contours.delete()
            hierarchy.delete()
        }

    } catch (err) {
        console.error('å¤„ç†è§†é¢‘å¸§æ—¶å‡ºé”™:', err)
        isProcessing = false
        // å‘ç”Ÿé”™è¯¯æ—¶å»¶è¿Ÿé‡è¯•ï¼Œä½†ä»éœ€æ£€æŸ¥isProcessingçŠ¶æ€
        if (isProcessing) {
            setTimeout(() => processVideoFrame(videoElement, canvasElement, ctx, stream), 1000)
        }
        return
    }

    // åœ¨å‡½æ•°æœ«å°¾å®‰æ’ä¸‹ä¸€å¸§å¤„ç†ï¼Œç¡®ä¿å¯ä»¥è¢«stopVideoProcessingæ­£ç¡®åœæ­¢
    if (isProcessing) {
        setTimeout(() => processVideoFrame(videoElement, canvasElement, ctx, stream), DETECTION_CONFIG.FRAME_RATE)
    }
}

// å¼€å§‹è§†é¢‘å¤„ç†å¾ªç¯
function startVideoProcessing(
    videoElement: HTMLVideoElement,
    canvasElement: HTMLCanvasElement,
    ctx: CanvasRenderingContext2D,
    stream: MediaStream | undefined
) {
    if (isProcessing) return
    isProcessing = true
    processVideoFrame(videoElement, canvasElement, ctx, stream)
}

// åœæ­¢è§†é¢‘å¤„ç†
function stopVideoProcessing() {
    isProcessing = false
}

// åˆå§‹åŒ–OpenCV
async function initializeOpenCV() {
    try {
        cv = await cvReadyPromise
        console.log('OpenCV.js åŠ è½½å®Œæˆ')
        return true
    } catch (error) {
        console.error('OpenCV.js åŠ è½½å¤±è´¥:', error)
        return false
    }
}

// é‡ç½®æ£€æµ‹çŠ¶æ€
function resetDetectionState() {
    lastValidCorners = null
    detectionHistory = []
    stableCount = 0
    noUpdateCount = 0
}

// è·å–å½“å‰æ£€æµ‹åˆ°çš„è¾¹æ¡†åæ ‡
function getCurrentDetectedCorners(): Point[] | null {
    return lastValidCorners ? [...lastValidCorners] : null
}

// è·å–é»˜è®¤è¾¹æ¡†åæ ‡ï¼ˆåŸºäºæ˜¾ç¤ºåŒºåŸŸçš„é»˜è®¤æ¡†ï¼‰
function getDefaultCorners(): Point[] {
    const { width, height } = displayArea.value
    const actualWidth = width || 640
    const actualHeight = height || 480

    // ä½¿ç”¨æ›´å°çš„è¾¹è·ï¼Œç¡®ä¿é»˜è®¤æ¡†èƒ½åŒ…å«æ›´å¤šå†…å®¹
    const margin = Math.min(actualWidth, actualHeight) * 0.05

    return [
        { x: margin, y: margin }, // å·¦ä¸Š
        { x: actualWidth - margin, y: margin }, // å³ä¸Š
        { x: actualWidth - margin, y: actualHeight - margin }, // å³ä¸‹
        { x: margin, y: actualHeight - margin } // å·¦ä¸‹
    ]
}

/**
 * é€è§†å˜æ¢æ ¡æ­£æ–‡æ¡£
 * @param imageData åŸå§‹å›¾åƒæ•°æ®
 * @param points å››ä¸ªè§’ç‚¹åæ ‡ [å·¦ä¸Š, å³ä¸Š, å³ä¸‹, å·¦ä¸‹]
 * @param outputWidth è¾“å‡ºå›¾åƒå®½åº¦ï¼ˆå¯é€‰ï¼Œè‡ªåŠ¨è®¡ç®—ï¼‰
 * @param outputHeight è¾“å‡ºå›¾åƒé«˜åº¦ï¼ˆå¯é€‰ï¼Œè‡ªåŠ¨è®¡ç®—ï¼‰
 * @returns æ ¡æ­£åçš„å›¾åƒæ•°æ®
 */
function perspectiveTransform(
    imageData: ImageData,
    points: Point[],
    outputWidth?: number,
    outputHeight?: number
): ImageData | null {
    if (!cv || points.length !== 4) return null

    try {
        // å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºå°ºå¯¸ï¼Œåˆ™è‡ªåŠ¨è®¡ç®—æœ€ä½³å°ºå¯¸
        if (!outputWidth || !outputHeight) {
            // è®¡ç®—å››è¾¹å½¢çš„å®½åº¦å’Œé«˜åº¦
            const topWidth = Math.sqrt(
                Math.pow(points[1].x - points[0].x, 2) +
                Math.pow(points[1].y - points[0].y, 2)
            )
            const bottomWidth = Math.sqrt(
                Math.pow(points[2].x - points[3].x, 2) +
                Math.pow(points[2].y - points[3].y, 2)
            )
            const leftHeight = Math.sqrt(
                Math.pow(points[3].x - points[0].x, 2) +
                Math.pow(points[3].y - points[0].y, 2)
            )
            const rightHeight = Math.sqrt(
                Math.pow(points[2].x - points[1].x, 2) +
                Math.pow(points[2].y - points[1].y, 2)
            )

            // ä½¿ç”¨æœ€å¤§å®½åº¦å’Œé«˜åº¦ä½œä¸ºè¾“å‡ºå°ºå¯¸
            outputWidth = Math.max(topWidth, bottomWidth)
            outputHeight = Math.max(leftHeight, rightHeight)

            // ç¡®ä¿è¾“å‡ºå°ºå¯¸ä¸ä¼šè¿‡å°æˆ–è¿‡å¤§ï¼Œä½†ä¿æŒå®½é«˜æ¯”
            const minSize = 200
            const maxSize = 2000

            // è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼Œç¡®ä¿æœ€å°è¾¹ä¸å°äºminSizeï¼Œæœ€å¤§è¾¹ä¸è¶…è¿‡maxSize
            const minScale = Math.max(minSize / outputWidth, minSize / outputHeight)
            const maxScale = Math.min(maxSize / outputWidth, maxSize / outputHeight)

            // åº”ç”¨ç¼©æ”¾ï¼Œä¼˜å…ˆä¿è¯æœ€å°å°ºå¯¸è¦æ±‚
            let scale = 1
            if (minScale > 1) {
                scale = minScale
            } else if (maxScale < 1) {
                scale = maxScale
            }

            outputWidth = Math.round(outputWidth * scale)
            outputHeight = Math.round(outputHeight * scale)
        }

        // åˆ›å»ºæºå›¾åƒçŸ©é˜µ
        const src = cv.matFromImageData(imageData)

        // å®šä¹‰æºç‚¹ï¼ˆæ£€æµ‹åˆ°çš„å››ä¸ªè§’ç‚¹ï¼‰
        const srcPoints = cv.matFromArray(4, 1, cv.CV_32FC2, [
            points[0].x, points[0].y,  // å·¦ä¸Š
            points[1].x, points[1].y,  // å³ä¸Š
            points[2].x, points[2].y,  // å³ä¸‹
            points[3].x, points[3].y   // å·¦ä¸‹
        ])

        // å®šä¹‰ç›®æ ‡ç‚¹ï¼ˆçŸ©å½¢çš„å››ä¸ªè§’ï¼‰
        const dstPoints = cv.matFromArray(4, 1, cv.CV_32FC2, [
            0, 0,                           // å·¦ä¸Š
            outputWidth, 0,                 // å³ä¸Š
            outputWidth, outputHeight,      // å³ä¸‹
            0, outputHeight                 // å·¦ä¸‹
        ])

        // è®¡ç®—é€è§†å˜æ¢çŸ©é˜µ
        const transformMatrix = cv.getPerspectiveTransform(srcPoints, dstPoints)

        // åˆ›å»ºè¾“å‡ºå›¾åƒ
        const dst = new cv.Mat()
        const dsize = new cv.Size(outputWidth, outputHeight)

        // æ‰§è¡Œé€è§†å˜æ¢
        cv.warpPerspective(src, dst, transformMatrix, dsize)

        // è½¬æ¢ä¸ºImageData
        const canvas = document.createElement('canvas')
        canvas.width = outputWidth
        canvas.height = outputHeight
        const ctx = canvas.getContext('2d')

        if (!ctx) {
            src.delete()
            srcPoints.delete()
            dstPoints.delete()
            transformMatrix.delete()
            dst.delete()
            return null
        }

        cv.imshow(canvas, dst)
        const correctedImageData = ctx.getImageData(0, 0, outputWidth, outputHeight)

        // æ·»åŠ è°ƒè¯•ä¿¡æ¯
        console.log('ğŸ“ é€è§†å˜æ¢å®Œæˆ:', {
            åŸå§‹å°ºå¯¸: `${imageData.width}x${imageData.height}`,
            è¾“å‡ºå°ºå¯¸: `${outputWidth}x${outputHeight}`,
            æ£€æµ‹ç‚¹: points
        })

        // æ¸…ç†å†…å­˜
        src.delete()
        srcPoints.delete()
        dstPoints.delete()
        transformMatrix.delete()
        dst.delete()

        return correctedImageData
    } catch (error) {
        console.error('é€è§†å˜æ¢å¤±è´¥:', error)
        return null
    }
}

export {
    // ç±»å‹å®šä¹‰
    type Point,
    type Corners,

    // å“åº”å¼å˜é‡
    videoWidth,
    videoHeight,
    containerWidth,
    containerHeight,
    displayArea,

    // å¸¸é‡
    DETECTION_CONFIG,

    // å·¥å…·å‡½æ•°
    scanner,

    // ä¸»è¦åŠŸèƒ½å‡½æ•°
    drawContourOnCanvas,
    processVideoFrame,
    startVideoProcessing,
    stopVideoProcessing,
    initializeOpenCV,
    resetDetectionState,
    getCurrentDetectedCorners,
    getDefaultCorners,
    perspectiveTransform
}